<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Hi, this is ExhYZ.</title>
        <link>https://www.nwyz.eu.org/blog/posts/</link>
        <description>Recent content in Posts on Hi, this is ExhYZ.</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Fri, 29 Mar 2024 00:41:52 +0800</lastBuildDate>
        <atom:link href="https://www.nwyz.eu.org/blog/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Responsible Designing AI</title>
            <link>https://www.nwyz.eu.org/blog/posts/7-responsible-designing-ai/</link>
            <pubDate>Fri, 29 Mar 2024 00:41:52 +0800</pubDate>
            
            <guid>https://www.nwyz.eu.org/blog/posts/7-responsible-designing-ai/</guid>
            <description>Hi, there. This is ExhYZ. As we increasingly rely on artificial intelligence in various aspects of our lives, it&amp;rsquo;s essential to consider the potential environmental impacts of these technologies. The use of AI could cause a lot of social problems and we may need to be aware of them and perhaps change some of our thinking. If you want to learn about these or get some of our development ideas and spirits, please be patient and read through this post.</description>
            <content type="html"><![CDATA[<p>Hi, there. This is ExhYZ. As we increasingly rely on artificial intelligence in various aspects of our lives, it&rsquo;s essential to consider the potential environmental impacts of these technologies. The use of AI could cause a lot of social problems and we may need to be aware of them and perhaps change some of our thinking. If you want to learn about these or get some of our development ideas and spirits, please be patient and read through this post.</p>
<h2 id="energy-consumption">Energy Consumption</h2>
<p>One of the most significant environmental concerns related to AI is its energy consumption. Training and running AI models require powerful computing systems that consume large amounts of electricity, which are typically generated by fossil fuels. This means that AI contributes to greenhouse gas emissions and climate change. The majority of experts concur that nuclear fusion will NOT play a significant role in reducing carbon emissions by mid-century, which is critical for combating the climate crisis. According to Helion&rsquo;s most optimistic projections, they will only produce enough energy to power 40,000 typical American households by 2029. On the other hand, an evaluation indicates that ChatGPT, the chatbot developed by OpenAI, is already using up the same amount of energy as 33,000 houses. Additionally, it is predicted that a generative AI-powered search consumes 4-5 times more energy than a standard online search. Large AI systems may eventually require as much energy as whole countries within a few years.<br>
<em>Refer to: <a href="https://www.nature.com/articles/d41586-024-00478-x">https://www.nature.com/articles/d41586-024-00478-x</a></em></p>
<p>It&rsquo;s not simply a matter of energy, though. Freshwater is needed in massive quantities by generative AI systems for processor cooling and electrical generation. For instance, a group of data centers in West Des Moines, Iowa, serves OpenAI&rsquo;s most sophisticated model, GPT-4. According to a lawsuit filed by local citizens, the cluster consumed around 6% of the area&rsquo;s water in July 2022, the month before OpenAI completed work on the model. Both Google and Microsoft saw substantial jumps in water consumption—increases of 20% and 34%, respectively—when they were preparing their Bard and Bing large language models, according to their environmental studies. By 2027, one preprint predicts that AI&rsquo;s global demand for water might reach half of the UK&rsquo;s needs.</p>
<p>I admit that Ethonwork does consume some of the energy used in the training of generative models, but our recent research has optimized the architecture of the training and the quantization of end-user models in order to reduce the use of energy at every step of the way, and we are calling for more large language models as well as image-generation models to use lightweight reasoning and fine-tuning frameworks such as llama.cpp. We have used small parameters less than 2 billion as a base for recent models such as the Wanfu 9H Spark and Xingfeng series, which have likewise yielded good results in testing as well as in use. We call for reducing the misuse of large AI models by using as much local input data as possible instead of class-zero-shot reasoning to reduce the excessive reliance on raw datasets for models that are a bit behind.</p>
<h2 id="misinformation">Misinformation</h2>
<p>In recent years, the dissemination of misinformation through AI has become a major problem, as I experienced in China. Deepfake technology, which uses machine learning algorithms to create convincingly lifelike images and videos, has gained popularity by enabling individuals to create increasingly sophisticated fake content, including videos on TikTok and other social media platforms. These fake videos often go viral, causing widespread confusion and misunderstanding among the public.</p>
<p>A particularly worrisome trend is the use of AI-generated fake videos to deceive unsuspecting victims. Scammers are using advanced AI algorithms to create fake videos that appear to feature well-known celebrities or influencers endorsing certain products or services. These videos are then widely shared on social media, often with the goal of persuading viewers to invest in the fraudulent scheme or hand over personal information.</p>
<p>Another issue is the rise of fake AI video calls, where scammers use AI-powered software to impersonate familiar voices or faces to deceive their targets. This can cause financial losses to individuals and businesses, as well as damage to reputations and relationships. The negative social impact of these fake videos and calls cannot be overstated. They erode trust in organizations, fuel conspiracy theories, and create an atmosphere of uncertainty and mistrust. In addition, they perpetuate harmful stereotypes and reinforce destructive social norms.</p>
<p>In response to this growing problem, the Chinese government has taken steps to combat misinformation spread through AI. These measures include increased regulation of online content, tougher penalties for those who create and disseminate false information, and greater investment in AI tools designed to detect and flag false content. In addition, awareness-raising campaigns aimed at educating the public about the dangers of misinformation and how to recognize it are being stepped up.</p>
<p>As a member of the community of model developers, we have made an effort to address and caution against potentially harmful data during training (although we don&rsquo;t have a strict ban in place). We exercise extra vigilance when it comes to creating large volumes of text or image-generating models. Ethonwork encourages model creators to provide warnings about this issue, with a special emphasis on open-source models. To ensure responsible use, we suggest incorporating consent agreements and tracking essential information whenever someone interacts with these models. While this may seem counterintuitive to the ethos of open-source development, it is crucial for safeguarding the model&rsquo;s integrity.</p>
<h2 id="job-loss">Job Loss</h2>
<p>AI-induced unemployment doesn&rsquo;t look like a big deal at this stage, but in an age where technology advances by the month or even the week, that moment could be coming soon.  According to recent research on AI and job loss from Zippia, a career data analysis organization , the global economy may experience significant job displacement due to the increasing use of artificial intelligence. The study suggested the fact that half of companies already have AI embedded in their business operations, and 27% of employees worry about losing their jobs to AI in the next five years. Moreover, 49% of people believe that AI has already led to job losses due to budget cuts and staff reduction.</p>
<p>The effects of AI on employment will vary across different countries. While the US is predicted to have a lower proportion of its workforce impacted significantly by technological advances compared to many European Union countries, the country is still expected to see a substantial effect. By 2030, 45 million Americans could lose their jobs to AI automation, representing approximately one-quarter of the workforce. Globally, a billion people could lose their jobs due to AI over the next decade.</p>
<p>Despite the potential negative consequences, AI can also bring numerous benefits. For instance, 19% of workers believe that AI can help alleviate the drudgery of their jobs, and 90% of tech executives agree that AI-powered machines will handle mundane tasks, allowing humans to focus on more creative work. Additionally, AI is predicted to create 97 million jobs and positively impact the economy by $15.7 trillion by 2030.</p>
<p>However, the transition to an AI-driven workforce will require significant investments in education and training. More than 120 million workers worldwide will need retraining and upskilling in the next three years to adapt to the changing job market. Furthermore, while AI can automate certain tasks, it cannot replace human judgment and decision-making entirely. Therefore, it is essential to develop strategies that enable workers to complement AI effectively.<br>
<em>Refer to: <a href="https://www.zippia.com/advice/ai-job-loss-statistics/">https://www.zippia.com/advice/ai-job-loss-statistics/</a></em></p>
<p>First of all, I DO NOT suggest that AI replacing human jobs will necessarily lead to a worse society, as long as we control it. What we can do as one of the model authors is to advocate for trying to do our jobs better through existing workers ASSISTED by AI, and for us, or most of the AIs on the market, completely replacing real human jobs is UNLIKELY at this stage. We are more advocates of promoting lifelong learning, as well as reducing our burden in social work through AI, and enabling more people to do their jobs faster and with higher quality through AI, in order to spend more of our life time on the people and things around us that NEED US, or to better enjoy our REAL LIVES.</p>
<p><strong>This is also part of the socialist advocate ideology of Ethonwork.</strong></p>
<h2 id="deliver-technologies-to-everyone">Deliver Technologies To Everyone</h2>
<p>One of Ethonwork&rsquo;s goals is to deliver the technology to everyone and make AI and other technologies accessible to more people, and to that end we train models such as the Spark family of small-parameter models, as well as small-parameter alternatives at the GPT level, which can be run on lower-computing devices such as old laptops or mobile phones, which, it is important to note, still dominate the world&rsquo;s computing landscape despite rapid technological advances. We advocate for more model developers to provide small parameter branches of their models, even though they may not bring much more revenue, and this is still one of the missing corners of the world&rsquo;s technology that we need to pay attention to and warm up to.</p>
<h2 id="build-an-open-future">Build An Open Future</h2>
<p>We advocate the development and use of open source software and technology, all of our models and frameworks are all open source, we do NOT want more vendors in the future to repeat the manufacture of &ldquo;wheels&rdquo;, but based on a better open base, and then improve and enhance, so as to accelerate technological progress in this regard, such as Meta, Google and other friends have made great contributions. We call for more hope through their own technology to promote the rapid development of software developers to open source more projects. We urgently need a more open world.</p>
<h2 id="stay-responsible">Stay Responsible</h2>
<p>Advocating for a responsible approach to the design of AI is essential to ensure that the development and use of these powerful technologies promotes the social good and minimizes harm. This requires consideration of the ethical implications of AI systems, such as their potential impact on privacy, equity, accountability and transparency. Responsible AI design requires a multidisciplinary approach, which entails the development of frameworks and guidelines to address issues such as data bias, algorithmic transparency and accountability, and to ensure that AI systems are consistent with human values and social norms. In addition, it requires continuous monitoring and evaluation of AI systems to identify unintended consequences and mitigate any negative impacts. By promoting responsible AI design, we can harness the power of these technologies to create a better future for all, while avoiding potentially disastrous consequences.</p>
]]></content>
        </item>
        
    </channel>
</rss>
